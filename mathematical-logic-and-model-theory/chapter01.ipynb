{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this chapter gives a very good summary of first order logic. Given it's very long and it's interleaved with details and big pictures, I'd like to extract out a big picture out of these pages, for future reference.\n",
    "\n",
    "## big picture of first order logic language.\n",
    "\n",
    "First, Section 1.2 defines a formal language that is only defined syntactically.\n",
    "\n",
    "Then Section 1.3 gives some synatical rules for doing deduction using this language.\n",
    "\n",
    "Therefore, the above two sections define a formal language and how to perform deductions using it. However, we haven't established any connection between play of characters as defined in these two Sections and  a mathematical proof that is meaningful to humans.\n",
    "\n",
    "In this book's terminology, we need to establish connection between axiom systems defined by formal languages and models (also called domains or mathematical structures).\n",
    "\n",
    "Sections 1.4 and 1.5 should be considered together. Section 1.4 is full of details, and the main conclusion is given in Section 1.5. In Section 1.5, first the authors define what a model (which is a structure) is. The essential key ideas are approximately as follows.\n",
    "\n",
    "* For an axiom system with language $L$, we can define various structures which assigns **unambiguously** a truth value (T/F) to every formula in the language $L$. In addition, this axiom system comes with axioms $\\Sigma$, which are formulas in $L$. Those structures that assign formulas in $\\Sigma$ to be true are called **models** of this axiom system.\n",
    "    * here I gloss over detaila such as formula vs. sentence, etc.\n",
    "\n",
    "\n",
    "Then two theorems are given (Thm  1.5.2 and Thm 1.5.4) relating an axiom system and models.\n",
    "\n",
    "* Thm 1.5.2 (Gödel's Completeness theorem): If an axiom system cannot derive a certain sentence $\\varphi$, then there must exist models where negation of $\\varphi$ is true. In other words, If all models of an axiom system has $\\varphi$ as true (has negation of $\\varphi$ as false), then it must be provable.\n",
    "* Thm 1.5.4 (soundness theorem): If some $\\varphi$ is provable, then all models of this axiom system has $\\varphi$ as true (has negation of $\\varphi$ as false).\n",
    "\n",
    "## other big picture level notes\n",
    "\n",
    "(NOT QUITE SURE)\n",
    "\n",
    "pp. 9\n",
    "\n",
    "> The metalanguage will always be the mathematical colloquial language, in which, for example, we occasionally use common abbreviations (such as “iff” for “if and only if”). In the metalanguage, we shall also use the set theoretical conceptual apparatus, as is usual in mathematics.\n",
    "\n",
    "I think one reason we can use set theory (plus some usual, colloquial math) to reason about object (formal) language is that we can derive set theory from it, as shown in Section 1.6. Since set theory can be formalized by formal language, the usual math can be formalized as well. Conceptually, this show that we can use formal language to prove itself. At least, it's kind of self-consistent. This is probably the best we can do, if we do not assume absolute truth of anything.\n",
    "\n",
    "Maybe, in Section 1.6, they prove that set theory can be formulated in a formal language, and this proof is all done using \"finitary reasoning\", that is clear and convincing. So at least we can show that, (assuming the formal language for set theory is consistent), that the formal language itself can be used to prove certain facts about formal language. This is probably the best thing we can do, as Gödel says consistency cannot be proved in itself (its second incompleteness theorem)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## details -- 1.2\n",
    "\n",
    "### pp. 10 definitions of term and formula.\n",
    "\n",
    "Here, the last part is \"No other strings of symbols ...\". This is OK here. Because, term and formula are defined recursively, and they can only become **LONGER** as we apply recursion. Therefore, we can always find an algorithm (that will terminiate) to check if a string is a term or formula (either it's atom, or apply each recursion; the string gets strictly shorter and shorter, and will become an atom in the end). If the definitions become more fancy, then we may have issue deciding whether a string is a term/formula or not.\n",
    "\n",
    "### pp. 12 replacement of variable and replacement of constant.\n",
    "\n",
    "Replacement of Var is defined in Eq. (1.2.0.8). Notice that, since a formula can contain parts like $\\forall u$, we may introduce additional **bounding** we don't choose $t$ carefully. This is easier to understand in programming language.\n",
    "\n",
    "```python\n",
    "c = 5\n",
    "def fun(a, b):\n",
    "    return a + b + c\n",
    "```\n",
    "\n",
    "Clearly. if we replace `c` with `b`, then the meaning of this snippet changes. That's essentially what this paragraph below is talking.\n",
    "\n",
    "> If a free occurrence of $v$ in the formula $\\varphi$ falls within the scope of a quantifier $\\forall u$, and if $u$ occurs somewhere in $t$, then after replacement of $v$ in $\\varphi$  by $t$, the variable $u$ will obviously fall within the scope of $\\forall u$.\n",
    "\n",
    "\"$t$ is free\" means $t$ should not contain `a` or `b`, in the above example. Here, notice that this free is defined w.r.t. a particular variable $v$. So \"not contain `a` or `b`\" is considered at all occurences of $v$.\n",
    "\n",
    "**In particular**, $v$ is free w.r.t. $v$ itself, by this definition, since no $v$ that falls within the scope fo some $\\forall v$ is free.\n",
    "\n",
    "> If this does not happen for any variable $u$ in $t$, then $t$ is called **free for $v$** in $\\varphi$. In other words, $t$ is free for $v$ in $\\varphi$ if no free occurrence of $v$ in $\\varphi$ lies within the scope of a quantifier $\\forall u$ used in the construction of $\\varphi$, where $u$ occurs in $t$.\n",
    "\n",
    "replacement of constant should not have these issues. as there's no notion of bounding here.\n",
    "\n",
    "### pp. 13 universal closure.\n",
    "\n",
    "By writing enough $\\forall$ outside, we can always convert a non-sentence to a sentence. Notice that you may have some $\\forall v_k$ that appears more than once; in that case, every $v_k$ is bound to the innermost $\\forall v_k$ it belongs to (just like programming language).\n",
    "\n",
    "```python\n",
    "def fun1(a, b):\n",
    "    b = 1\n",
    "    def fun2(a, b):\n",
    "        return a + b \n",
    "```\n",
    "\n",
    "in this example, `a` in `fun1` is useless. first `b` is bound to `fun1`, and second `b` to `fun2`.\n",
    "\n",
    "### pp. 13 definition of language.\n",
    "\n",
    "Eqs. (1.2.0.10) and (1.2.0.11).  Compare this with relation symbols, function symbols, and constant symbols in pp. 9. Since these symbols are just symbols, so Eq. (1.2.0.10) essentially contains all the information of those three types of symbols in pp. 9 (all symbols are distinct, but we don't assign any other meaning to them).\n",
    "\n",
    "The essense of the language is as follows.\n",
    "\n",
    "1. how many relations (just symbol) and their \"signature\" (programming language jargon; how many args). this is defined by $I$, or domain of $\\lambda$.\n",
    "2. how many functions (just symbol), and their \"signature\". this is defined by $J$, or domain of $\\mu$.\n",
    "3. how many constants (just symbol). this is defined by $K$.\n",
    "\n",
    "variables have an index set of natural number as shown in pp. 9.\n",
    "\n",
    "> The concepts of our formal language that we have introduced in this section depend upon three quantities, which we fixed earlier in this section ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## details -- 1.3\n",
    "\n",
    "this sections gives details on logic axioms and rules. Remember, for the sake of this book, only consider them for their syntax. Don't attribute any concrete meaning to them.\n",
    "\n",
    "### pp. 15 - 17 logical axioms\n",
    "\n",
    "three types of logical axioms.\n",
    "\n",
    "1. tautologies. Basically, regardless how you assign (finite number of) sentential variables, they should be always true.\n",
    "2. Eqs. (1.3.0.7) and (1.3.0.8). Notice the free issue. Please just consider them in their **pure syntactical sense**, although they make sense.\n",
    "3. Eqs. (1.3.0.9). Again, make sense. But just understand them pure synatically. Notice that here all $v,x,u$ etc. are variables, not terms. that is why Eq. (1.3.0.18)'s proof, which starts at Eq. (1.3.0.20), has to be that complicated:  Eq. (1.3.0.9) is about variables. $t$'s in Eq. (1.3.0.18) are terms.\n",
    "\n",
    "\n",
    "Note that informally I call all logical axioms tautologies, as I personally understand \"tautology\" as something that is true. Here it's not the case. In particular, \"tautological form\" doesn't have quantifiers ($\\forall, \\exists$), and instance of tautological form (or tautology) replaces each sentential variable with a formula. Since tautological forms don't have quantifiers, the instances should not have any issue of variable binding even though they may themselves contain variables and quantifiers.\n",
    "\n",
    "### pp. 17 logical rules\n",
    "\n",
    "There are only two. MP and generalization.\n",
    "\n",
    "For generalization. If $x$ is not free in $\\varphi$, then it trivially holds (semantically); if not, well... just assume that this is the convention. So this generalization rule means that, if we say $x = y$ holds, then we have $\\forall x \\forall y \\ \\  x=y$. Not sure if such syntactical design of logical rule makes sense or not. It is like implicitly all formulae with free variables have appropriate numbers of $\\forall$ outside (semantically).\n",
    "\n",
    "### pp. 23 work on sentences only\n",
    "\n",
    "Lemma 1.3.1 shows that there is no difference between formula and its universal closure.\n",
    "\n",
    "> By repeated use of Lemma 1.3.1(a), we see that the derivability of a formula $\\varphi$ from $\\Sigma$ is equivalent to the derivability of its universal closure $\\forall\\varphi$ (p. 13) from $\\Sigma$. Similarly, repeated use of Lemma 1.3.1(b) permits us to replace all formulae in $\\Sigma$ by their universal closures.\n",
    "\n",
    "I think essentially this is caused by the particular design of generalization rule, which basically makes a formula and its universal closure equiavalent.\n",
    "\n",
    ">  On the basis of this, we shall often, in the future, limit ourselves to the case where $\\Sigma$ is a set of sentences, and $\\varphi$ is a sentence.\n",
    "\n",
    "### pp. 24 deduction theorem.\n",
    "\n",
    "basically, this theorem talks about when we can moving $\\varphi$ out of axioms (Check pp. 24 for symbols' meanings); the other direction is always doable.\n",
    "\n",
    "I think semantically, this makes much sense: if we assume $A$ and under such circumstances prove $B$, then we have $A \\rightarrow B$. However, this theorem makes it precise that this happens only when $A$ has no free variable.\n",
    "\n",
    "#### errata.\n",
    "\n",
    "* Eq. (1.3.2.1) misses a \"(\". it should be in front of $(\\varphi \\rightarrow \\varphi_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### details -- 1.4\n",
    "\n",
    "#### pp. 25 whether this formal, syntatical system is useful\n",
    "\n",
    "> It remains to clarify the question of whether this definition really captures what one ordinarily understands by a proof.\n",
    "\n",
    "One thing that they claim is not the critical weakness is the expressive power. However I don't know how you properly define \"expressive power\". They say that they can use this formal syntatical system to \"formalize set theory\". However what is the exact definition of \"formalize\"? Let's assume that set theory has 10 axioms, and let's say you constructed 10 pure syntactical forms in your system to correspond to those 10 set theory axioms. How can we know that they are really corresponding? They may look corresponding, but how do you know this correspondence is exact? By exact, I mean there is some isomorphism between everything in set theory and everything in the formal system. I personally feel that such isomorphism might be very difficult to argue for. Best example would be that we have no formal system to be able to exactly correspond to the notion of natural numbers (what Godel's incompleteness theorem talks about), although we can come up with some formal representation that matches our intuition well (Peano arithimetic), but not natural numbers per se. So this \"expressive power\" thing isn't really well defined.\n",
    "\n",
    "> A further possible objection could be that the formal languages we use have inadequate expressive power. in Section 1.6 we shall formalize set theory in such a language. \n",
    "\n",
    "Notice that while set theory can be used to construct natural numbers, the set theory does not say that there is THE set of natural numbers. Possibly, there can be multiple sets of elements satisfying its definition of natural numbers. Check <https://math.stackexchange.com/questions/2251117/how-do-we-know-what-natural-numbers-are>.\n",
    "\n",
    "#### pp. 26 completeness and soundness.\n",
    "\n",
    "* soundness means that all proofs derived from our formal, syntatical system really holds.\n",
    "* completeness means that our system can prove everything that is provable.\n",
    "\n",
    "These two things are said w.r.t. to some domain (or structure), where the domain's axioms satisfy a formal system's axioms (a domain satisfying a formal system's axioms is a model of that axiom system; pp. 36, Section 1.5, first 3 lines). Check my details on domain vs structure.\n",
    "\n",
    "The main conclusion from this chapter is (1.4.0.2).\n",
    "\n",
    "> Any unprovability rests necessarily on a counterexample.\n",
    "\n",
    "So our formal system is complete.\n",
    "\n",
    "#### pp. 26 inconsistency means we can prove anything.\n",
    "\n",
    "This is (1.4.0.3). Here, this \"prove anything\" is pure **syntatical**.\n",
    "\n",
    "* For the \"if\" part, let $\\beta$ once be $\\alpha$ and once negation of $\\alpha$, then we are done, using definition of inconsistency.\n",
    "* for the only if part, check the proof given in the book Eqs. (1.4.0.4-1.4.0.5).\n",
    "\n",
    "#### pp. 26 unprovability means its negation being consistent with the rest.\n",
    "\n",
    "This is what Lemma 1.4.1 says. If we can't prove something from a set of axioms $\\Sigma$, that means that the negation of this something is compatible with $\\Sigma$.\n",
    "\n",
    "#### pp. 27 main approach to show that unprovability is real due to counterexample.\n",
    "\n",
    "This is what (1.4.1.3) says.\n",
    "\n",
    "> to construct, for any consistent set $\\Sigma$ of sentences, a domain in which all $\\sigma \\in \\Sigma$ hold.\n",
    "\n",
    "Here $\\Sigma$ is the union of $\\Sigma$ and negation of $\\varphi$ in the above (check footnote 2). Since here we are talking about a domain, every sentence in it is either true or false, and it's consistent by construction (consistent here means that you can't assign both true and false to a sentence by the way we construct a domain; see 1.5). Therefore, since we prove that a domain where negation $\\varphi$ is true (since it's in the axiom of the domain, \"all $\\sigma \\in \\Sigma$ hold\"), we automatically know that $\\varphi$ is false, by construction. So we find a counterexample to explicitly establish the unprovability of $\\varphi$.\n",
    "\n",
    "\n",
    "**The main outline of proof** is this.\n",
    "\n",
    "1. in this Section, using Thms 1.4.2 and 1.4.4, we expand a language $L$ with axioms $\\Sigma$ to $L'$ with axioms $\\Sigma^*$.\n",
    "2. in next Section, we will prove that there exists a model for  $L'$ and $\\Sigma^*$.\n",
    "3. finally, this model is also a model for $L$ and $\\Sigma$ (after removing those additional constants introduced by $L'$ relative to $L$). The model's evaluation on those $L$-subset of $L'$ doesn't change, and $\\Sigma$ is a subset of $\\Sigma^*$. So the original model is still a model after removing those additional constants introduced by $L'$ relative to $L$.\n",
    "\n",
    "The reason we need to first expand (to $L'$ and $\\Sigma^*$) and then contract (back to $L$ and $\\Sigma$) is because otherwise it might be difficult to claim that the model exists. For example, in the proof of statement (1.5.2.5) in pp. 42, they make use of (1.4.7), which probably won't hold on $L$ and $\\Sigma$.\n",
    "\n",
    "This book uses this particular expansion; not sure if other expansion exists.\n",
    "\n",
    "\n",
    "#### pp. 27 Thm 1.4.2: Step 1 to show (1.4.1.3) -- (syntactical) existence sentence can be always backed up by some (syntactical) concrete example, by adding more constants and axioms.\n",
    "\n",
    "This is what Thm 1.4.2 talks about. I say \"by adding more constants and axioms\" because this backing up needs $K'$ and $\\Sigma'$.\n",
    "\n",
    "##### helper lemma. Lemma 1.4.3: a proof with an additional constant can be reduced to one without by replacing that constant throughout the proof and the axioms.\n",
    "\n",
    "This is what Lemma 1.4.3 talks about. Notice that in pp. 28 we have\n",
    "\n",
    "> $\\Psi(x/t)(c_0/y)$ is just $\\Psi(c_0/y)(x/t(c_0/y))$.\n",
    "\n",
    "this always looks weird. But basically, it's there to make sure that the replacing process keeps a quantifier axiom to be still a quantifier axiom. $y$ doesn't affect anything, as $y$ is always free here (since it's new), and it won't affect anything related to freeness or not whether we replace it first or later or whatever.\n",
    "\n",
    "##### pp. 28-32 overview of the proof.\n",
    "\n",
    "Overall, they construct such a $\\Sigma'$ by unioning over a sequence of $\\Sigma_n$. Because each of $\\Sigma_n$ is shown to be consistent via the helper lemma above, they can argue that $\\Sigma'$ is consistent. By construction, $\\Sigma'$ has those concrete example sentences in it.\n",
    "\n",
    "1. To construct sequence of $\\Sigma_n$, they defined a sequence of new constants $M_n$ (1.4.3.1).\n",
    "   * Here, each new constant has a bijection (one-to-one correspondence) with existential sentences of $L_{n-1}$. Notice that the very same sentence can be mapped to multiple constants, due to one sentence can appear in both $L_i$ and $L_j$. This bijection is associated with a function that maps constant to sentence. They claim that \"Sets $M_n$ and bijections $g_n$ of the required kind always exist\". One way to define it is to set $M_n$ to be $(n, x), x \\in  \\{\\exists x \\varphi\\}$. Here, we basically use sentences themselves, plus $n$, to correspond to constants in $M_n$. One may informally say that we use the sentence's name (its written form) as the index set of constants; however, this is not realizable in practice, as the set of (existential) sentences may be uncountable in our case, and we cannot write down all the names (if we can, then there's a way to create bijection between natural numbers and these existential sentences, which is impossible as we said the set of these sentences are uncountable). **Maybe Check Peter Smith’s Intro to Godel’s theorem book to make my thinking here more precise.**\n",
    "2. Then they defined the sequence of $\\Sigma_n$ in Eq. (1.4.3.5).\n",
    "3. Then they try to prove that such of $\\Sigma_n$ is consistent, assuming that $\\Sigma_{n-1}$ is consistent. To prove this, following steps are taken.\n",
    "    1. assuming $\\Sigma_n$ is inconsistent. That means that $\\Sigma_{n-1}$'s union with some sentences involving new constants from $M_n$ is inconsistent. by Eq. (1.4.3.5).\n",
    "    2. Moreover, by the **finiteness** of proof, we can trace the inconsistency back to a finite set of new sentences. This is what (1.4.3.6) talks about. The math expression below (1.4.3.6) gives the starting point of our assumption.\n",
    "    3. starting from the starting point, we can 1) use deduction theorem and 2) use the helper lemma to show that we can show inconsistency of the axiom system with one fewer axiom than our starting point. The unspecified $\\alpha$ and its negation becomes some tranformation of that removed axiom.\n",
    "    4. We can do this repeatedly and show the inconsistency of $\\Sigma_{n-1}$. DONE.\n",
    "\n",
    "> Just as we have reduced the inconsistency of $\\Sigma_{n-1} \\cup  \\{ \\sigma_1,\\ldots,\\sigma_r \\}$ to that of $\\Sigma_{n-1} \\cup  \\{ \\sigma_2,\\ldots,\\sigma_r \\}$, we can, through iteration, finally deduce a contradiction already in $\\Sigma_{n-1}$. Since this contradicts our hypothesis, the consistency of Σn follows. In this way, all the $\\Sigma_{n}$ are recognized as consistent.\n",
    "\n",
    "#### pp. 32 Thm 1.4.4: Step 2 to show (1.4.1.3) -- (semantic) existence of a domain that \n",
    " \n",
    "Thm (1.4.4) finds, for each consistent set $\\Sigma$, a **maximal** (not maximum, which is stronger; check <https://en.wikipedia.org/wiki/Maximal_and_minimal_elements>) extension; this extension corresponds to some domain. I think it's best to check out definition of domain first below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### details -- 1.5\n",
    "\n",
    "#### pp. 36-41 definition of a structure/domain, and what it means to be a model.\n",
    "\n",
    "As defined in pp. 37, we have four parts of a structure: universe, and definitions of relations, functions and constants on that universe. I think \"domain\" sometimes refers to the universe, sometimes equivalent to structure (a collection of four) in this book; structure always refers to the collection of four.\n",
    "\n",
    "##### pp. 37-38. you need both four parts structure and an evaluation function to determine every formula's truth value.\n",
    "\n",
    "The 4-part structure doesn't specify the value of those variables. We also need to specify variables' values. Given in lower part of pp. 37, $h$ defines a mapping from variable (which has isomorphism to natural numbers) to the universe. $h \\binom{x}{a}$ is another evaluation function based on $h$ that only possibly differs on $x$.\n",
    "\n",
    "> The satisfaction of a formula $\\varphi$ under an evaluation $h$ in $\\mathcal{U}$ will be a ternary relation of our metatheory.\n",
    "\n",
    "key thing is that, for a structure together with some evaluation function, there is a definitive truth value for every term and formula. term takes value in the universe; formula takes value of true/false (this is why they talk about satisfication of a formula, but not term). Since our definition of formula and term is recursive, and longer ones are always **uniquely** decomposed into shorter pieces, so longer ones have definitive values.\n",
    "\n",
    "\n",
    "##### pp. 39 lemma 1.5.1 only free variables matter.\n",
    "\n",
    "* terms have no notion of free variable; or all are free. So we need two evaluation functions to be exactly the same for their evaluations of the same term to be the same.\n",
    "* for formula, we only need free variables to match, as we need to unfix those bound ones anyway.\n",
    "\n",
    "The proofs involves recursion. This is possible because longer formula can be decomposed **uniquely** into shorter ones. That the theorem holds for shorter ones become the induction hypothesis. If longer formula cannot be decomposed uniquely, we may have more troubles in the proof (at least more cases to consider).\n",
    "\n",
    "##### pp. 40-41 evaluation function doesn't matter for sentences.\n",
    "\n",
    "as sentences don't have free variables. Check (1.5.1.3).\n",
    "\n",
    "> in particular, that the satisfaction of a sentence $\\varphi$ in $\\mathcal{U}$ does not depend on the evaluation $h$ considered.\n",
    "\n",
    "The statement between (1.5.1.3) and (1.5.1.4), as well as (1.5.1.4) say that adding $\\forall$ outside won't change a **formula**'s truth value, if evaluated against ALL $h$.\n",
    "\n",
    "\n",
    "(1.5.1.4) can be used recursively to prove the statement between (1.5.1.3) and (1.5.1.4). Every time we are done with setting a new variable outside, we set new $\\varphi$ to $\\forall x \\varphi$, and add a new variable to work on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
